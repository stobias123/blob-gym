{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from util import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "from tf_agents.agents.categorical_dqn import categorical_dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import categorical_q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load our custom gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register\n",
    "\n",
    "register(\n",
    "    id='blob2d-v1',\n",
    "    entry_point='blob_env.envs.blob_env:BlobEnv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set our hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name='blob2d-v1' # @param {type:\"string\"}\n",
    "num_iterations = 15000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 10000  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1000  # @param {type:\"integer\"}\n",
    "replay_buffer_capacity = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "gamma = 0.99\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_atoms = 51  # @param {type:\"integer\"}\n",
    "min_q_value = -300  # @param {type:\"integer\"}\n",
    "max_q_value = 25  # @param {type:\"integer\"}\n",
    "n_step_update = 2  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 100  # @param {type:\"integer\"}\n",
    "eval_interval = 10000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create our environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(suite_gym.load(env_name))\n",
    "eval_env = tf_py_environment.TFPyEnvironment(suite_gym.load(env_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up our Categorical DQN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_q_net = categorical_q_network.CategoricalQNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    num_atoms=num_atoms,\n",
    "    fc_layer_params=fc_layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.compat.v2.Variable(0)\n",
    "\n",
    "agent = categorical_dqn_agent.CategoricalDqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    categorical_q_network=categorical_q_net,\n",
    "    optimizer=optimizer,\n",
    "    min_q_value=min_q_value,\n",
    "    max_q_value=max_q_value,\n",
    "    n_step_update=n_step_update,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    gamma=gamma,\n",
    "    train_step_counter=train_step_counter)\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "# Please also see the metrics module for standard implementations of different\n",
    "# metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics example\n",
    "Show the avg return of a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py:1004: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/autograph/operators/control_flow.py:1004: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)\n",
    "\n",
    "def collect_step(environment, policy):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  next_time_step = environment.step(action_step.action)\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  replay_buffer.add_batch(traj)\n",
    "\n",
    "for _ in range(initial_collect_steps):\n",
    "  collect_step(train_env, random_policy)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations of\n",
    "# these. For more details see the drivers module.\n",
    "\n",
    "# Dataset generates trajectories with shape [BxTx...] where\n",
    "# T = n_step_update + 1.\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, sample_batch_size=batch_size,\n",
    "    num_steps=n_step_update + 1).prefetch(3)\n",
    "\n",
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 200: loss = 0.10143177211284637\n",
      "step = 400: loss = 0.01126097235828638\n",
      "step = 600: loss = 0.011471697129309177\n",
      "step = 800: loss = 0.008756989613175392\n",
      "step = 1000: loss = 0.0405343659222126\n",
      "step = 1000: Average Return = -1.00\n",
      "step = 1200: loss = 0.02007431723177433\n",
      "step = 1400: loss = 0.04887240380048752\n",
      "step = 1600: loss = 0.023535801097750664\n",
      "step = 1800: loss = 0.00809444859623909\n",
      "step = 2000: loss = 0.014444164000451565\n",
      "step = 2000: Average Return = -1.00\n",
      "step = 2200: loss = 0.019560761749744415\n",
      "step = 2400: loss = 0.00663848128169775\n",
      "step = 2600: loss = 0.03202320262789726\n",
      "step = 2800: loss = 0.022702939808368683\n",
      "step = 3000: loss = 0.02733900398015976\n",
      "step = 3000: Average Return = -1.00\n",
      "step = 3200: loss = 0.02351500652730465\n",
      "step = 3400: loss = 0.006477363407611847\n",
      "step = 3600: loss = 0.006958630867302418\n",
      "step = 3800: loss = 0.018734116107225418\n",
      "step = 4000: loss = 0.014583170413970947\n",
      "step = 4000: Average Return = -1.00\n",
      "step = 4200: loss = 0.07142440974712372\n",
      "step = 4400: loss = 0.017170358449220657\n",
      "step = 4600: loss = 0.008986026048660278\n",
      "step = 4800: loss = 0.007866336032748222\n",
      "step = 5000: loss = 0.04972564056515694\n",
      "step = 5000: Average Return = -1.00\n",
      "step = 5200: loss = 0.007849114015698433\n",
      "step = 5400: loss = 0.007728618569672108\n",
      "step = 5600: loss = 0.008800928480923176\n",
      "step = 5800: loss = 0.008728595450520515\n",
      "step = 6000: loss = 0.008605848997831345\n",
      "step = 6000: Average Return = -30.90\n",
      "step = 6200: loss = 0.0074590714648365974\n",
      "step = 6400: loss = 0.006661645136773586\n",
      "step = 6600: loss = 0.009908627718687057\n",
      "step = 6800: loss = 0.006915985606610775\n",
      "step = 7000: loss = 0.006403823383152485\n",
      "step = 7000: Average Return = -1.00\n",
      "step = 7200: loss = 0.006929377093911171\n",
      "step = 7400: loss = 0.007268801331520081\n",
      "step = 7600: loss = 0.007561282720416784\n",
      "step = 7800: loss = 0.013062926009297371\n",
      "step = 8000: loss = 0.026653999462723732\n",
      "step = 8000: Average Return = -1.00\n",
      "step = 8200: loss = 0.007638320326805115\n",
      "step = 8400: loss = 0.014511575922369957\n",
      "step = 8600: loss = 0.006645768880844116\n",
      "step = 8800: loss = 0.005730347242206335\n",
      "step = 9000: loss = 0.00723239267244935\n",
      "step = 9000: Average Return = -1.00\n",
      "step = 9200: loss = 0.007178468629717827\n",
      "step = 9400: loss = 0.006370829418301582\n",
      "step = 9600: loss = 0.004854233469814062\n",
      "step = 9800: loss = 0.01724817603826523\n",
      "step = 10000: loss = 0.01406170055270195\n",
      "step = 10000: Average Return = -30.90\n",
      "step = 10200: loss = 0.00647913059219718\n",
      "step = 10400: loss = 0.018253467977046967\n",
      "step = 10600: loss = 0.03163069859147072\n",
      "step = 10800: loss = 0.006369650363922119\n",
      "step = 11000: loss = 0.007227747701108456\n",
      "step = 11000: Average Return = -1.00\n",
      "step = 11200: loss = 0.006083610467612743\n",
      "step = 11400: loss = 0.008585311472415924\n",
      "step = 11600: loss = 0.00899031013250351\n",
      "step = 11800: loss = 0.024366220459342003\n",
      "step = 12000: loss = 0.005953194573521614\n",
      "step = 12000: Average Return = -1.00\n",
      "step = 12200: loss = 0.02216995880007744\n",
      "step = 12400: loss = 0.006671682000160217\n",
      "step = 12600: loss = 0.03181151673197746\n",
      "step = 12800: loss = 0.020388497039675713\n",
      "step = 13000: loss = 0.011257370933890343\n",
      "step = 13000: Average Return = 1.60\n",
      "step = 13200: loss = 0.007492230739444494\n",
      "step = 13400: loss = 0.011746499687433243\n",
      "step = 13600: loss = 0.007368900813162327\n",
      "step = 13800: loss = 0.006771565414965153\n",
      "step = 14000: loss = 0.04386316239833832\n",
      "step = 14000: Average Return = -1.00\n",
      "step = 14200: loss = 0.027913659811019897\n",
      "step = 14400: loss = 0.022294458001852036\n",
      "step = 14600: loss = 0.007373114116489887\n",
      "step = 14800: loss = 0.006201932206749916\n",
      "step = 15000: loss = 0.04131888970732689\n",
      "step = 15000: Average Return = -1.00\n",
      "step = 15200: loss = 0.00680304691195488\n",
      "step = 15400: loss = 0.027472203597426414\n",
      "step = 15600: loss = 0.007879780605435371\n",
      "step = 15800: loss = 0.025181908160448074\n",
      "step = 16000: loss = 0.005930304527282715\n",
      "step = 16000: Average Return = -1.00\n",
      "step = 16200: loss = 0.007759499829262495\n",
      "step = 16400: loss = 0.0720629170536995\n",
      "step = 16600: loss = 0.00726782251149416\n",
      "step = 16800: loss = 0.007688112556934357\n",
      "step = 17000: loss = 0.01824246346950531\n",
      "step = 17000: Average Return = -1.00\n",
      "step = 17200: loss = 0.024107549339532852\n",
      "step = 17400: loss = 0.006362259853631258\n",
      "step = 17600: loss = 0.00453509297221899\n",
      "step = 17800: loss = 0.035303063690662384\n",
      "step = 18000: loss = 0.006877605803310871\n",
      "step = 18000: Average Return = -1.00\n",
      "step = 18200: loss = 0.0068405563943088055\n",
      "step = 18400: loss = 0.019246498122811317\n",
      "step = 18600: loss = 0.02338358201086521\n",
      "step = 18800: loss = 0.014716009609401226\n",
      "step = 19000: loss = 0.005014367867261171\n",
      "step = 19000: Average Return = -1.00\n",
      "step = 19200: loss = 0.005482933484017849\n",
      "step = 19400: loss = 0.018389996141195297\n",
      "step = 19600: loss = 0.006578141823410988\n",
      "step = 19800: loss = 0.00592517014592886\n",
      "step = 20000: loss = 0.007143552415072918\n",
      "step = 20000: Average Return = -1.00\n",
      "step = 20200: loss = 0.00692401546984911\n",
      "step = 20400: loss = 0.026486895978450775\n",
      "step = 20600: loss = 0.0196978822350502\n",
      "step = 20800: loss = 0.007520855404436588\n",
      "step = 21000: loss = 0.004833797924220562\n",
      "step = 21000: Average Return = -1.00\n",
      "step = 21200: loss = 0.007341934833675623\n",
      "step = 21400: loss = 0.06164783239364624\n",
      "step = 21600: loss = 0.007258948870003223\n",
      "step = 21800: loss = 0.035994306206703186\n",
      "step = 22000: loss = 0.0062042116187512875\n",
      "step = 22000: Average Return = -1.00\n",
      "step = 22200: loss = 0.008168818429112434\n",
      "step = 22400: loss = 0.03399696573615074\n",
      "step = 22600: loss = 0.017335914075374603\n",
      "step = 22800: loss = 0.005989672616124153\n",
      "step = 23000: loss = 0.007103391457349062\n",
      "step = 23000: Average Return = -1.00\n",
      "step = 23200: loss = 0.007573302369564772\n",
      "step = 23400: loss = 0.007745041511952877\n",
      "step = 23600: loss = 0.006634736433625221\n",
      "step = 23800: loss = 0.004319218918681145\n",
      "step = 24000: loss = 0.007215173449367285\n",
      "step = 24000: Average Return = -1.00\n",
      "step = 24200: loss = 0.013323770835995674\n",
      "step = 24400: loss = 0.011774254031479359\n",
      "step = 24600: loss = 0.012672784738242626\n",
      "step = 24800: loss = 0.006800070870667696\n",
      "step = 25000: loss = 0.015086565166711807\n",
      "step = 25000: Average Return = -1.00\n",
      "step = 25200: loss = 0.005870873108506203\n",
      "step = 25400: loss = 0.007452799938619137\n",
      "step = 25600: loss = 0.014418436214327812\n",
      "step = 25800: loss = 0.010570668615400791\n",
      "step = 26000: loss = 0.00648569455370307\n",
      "step = 26000: Average Return = -1.00\n",
      "step = 26200: loss = 0.006515651009976864\n",
      "step = 26400: loss = 0.03632437437772751\n",
      "step = 26600: loss = 0.05782759189605713\n",
      "step = 26800: loss = 0.0064972927793860435\n",
      "step = 27000: loss = 0.00804813951253891\n",
      "step = 27000: Average Return = -30.90\n",
      "step = 27200: loss = 0.005508178845047951\n",
      "step = 27400: loss = 0.006621562875807285\n",
      "step = 27600: loss = 0.01807054691016674\n",
      "step = 27800: loss = 0.020826026797294617\n",
      "step = 28000: loss = 0.01675177365541458\n",
      "step = 28000: Average Return = -1.00\n",
      "step = 28200: loss = 0.005675123073160648\n",
      "step = 28400: loss = 0.006265382282435894\n",
      "step = 28600: loss = 0.008206276223063469\n",
      "step = 28800: loss = 0.04387905076146126\n",
      "step = 29000: loss = 0.025867504999041557\n",
      "step = 29000: Average Return = -1.00\n",
      "step = 29200: loss = 0.010659970343112946\n",
      "step = 29400: loss = 0.03155466541647911\n",
      "step = 29600: loss = 0.007446161471307278\n",
      "step = 29800: loss = 0.006618155166506767\n",
      "step = 30000: loss = 0.00676795095205307\n",
      "step = 30000: Average Return = -1.00\n",
      "step = 30200: loss = 0.0072291549295187\n",
      "step = 30400: loss = 0.011855009943246841\n",
      "step = 30600: loss = 0.006509594619274139\n",
      "step = 30800: loss = 0.008729756809771061\n",
      "step = 31000: loss = 0.00877382606267929\n",
      "step = 31000: Average Return = -1.00\n",
      "step = 31200: loss = 0.013899749144911766\n",
      "step = 31400: loss = 0.023575350642204285\n",
      "step = 31600: loss = 0.006920126266777515\n",
      "step = 31800: loss = 0.009983557276427746\n",
      "step = 32000: loss = 0.02025439590215683\n",
      "step = 32000: Average Return = -1.00\n",
      "step = 32200: loss = 0.4942334294319153\n",
      "step = 32400: loss = 0.00720454566180706\n",
      "step = 32600: loss = 0.006956927478313446\n",
      "step = 32800: loss = 0.0065276166424155235\n",
      "step = 33000: loss = 0.01848510093986988\n",
      "step = 33000: Average Return = -1.00\n",
      "step = 33200: loss = 0.017101174220442772\n",
      "step = 33400: loss = 0.028248948976397514\n",
      "step = 33600: loss = 0.00959441065788269\n",
      "step = 33800: loss = 0.054269302636384964\n",
      "step = 34000: loss = 0.005779752973467112\n",
      "step = 34000: Average Return = -30.90\n",
      "step = 34200: loss = 0.0067902193404734135\n",
      "step = 34400: loss = 0.006418270990252495\n",
      "step = 34600: loss = 0.09949338436126709\n",
      "step = 34800: loss = 0.004395360127091408\n",
      "step = 35000: loss = 0.020951304584741592\n",
      "step = 35000: Average Return = 1.60\n",
      "step = 35200: loss = 0.007377189584076405\n",
      "step = 35400: loss = 0.0077575575560331345\n",
      "step = 35600: loss = 0.020698504522442818\n",
      "step = 35800: loss = 0.006019107066094875\n",
      "step = 36000: loss = 0.08000390976667404\n",
      "step = 36000: Average Return = -1.00\n",
      "step = 36200: loss = 0.006157143507152796\n",
      "step = 36400: loss = 0.0058462899178266525\n",
      "step = 36600: loss = 0.025071553885936737\n",
      "step = 36800: loss = 0.005419212393462658\n",
      "step = 37000: loss = 0.007260321639478207\n",
      "step = 37000: Average Return = 1.60\n",
      "step = 37200: loss = 0.023443762212991714\n",
      "step = 37400: loss = 0.01969737373292446\n",
      "step = 37600: loss = 0.022647220641374588\n",
      "step = 37800: loss = 0.051505155861377716\n",
      "step = 38000: loss = 0.009196273051202297\n",
      "step = 38000: Average Return = -30.90\n",
      "step = 38200: loss = 0.005238411016762257\n",
      "step = 38400: loss = 0.005842199549078941\n",
      "step = 38600: loss = 0.006637756247073412\n",
      "step = 38800: loss = 0.06079289689660072\n",
      "step = 39000: loss = 0.005850324407219887\n",
      "step = 39000: Average Return = -1.00\n",
      "step = 39200: loss = 0.037683695554733276\n",
      "step = 39400: loss = 0.007247556000947952\n",
      "step = 39600: loss = 0.009968098253011703\n",
      "step = 39800: loss = 0.010113203898072243\n",
      "step = 40000: loss = 0.008127650246024132\n",
      "step = 40000: Average Return = -1.00\n",
      "step = 40200: loss = 0.005761412903666496\n",
      "step = 40400: loss = 0.016839131712913513\n",
      "step = 40600: loss = 0.011688540689647198\n",
      "step = 40800: loss = 0.0073744673281908035\n",
      "step = 41000: loss = 0.007811985444277525\n",
      "step = 41000: Average Return = -1.00\n",
      "step = 41200: loss = 0.005613149609416723\n",
      "step = 41400: loss = 0.007306407205760479\n",
      "step = 41600: loss = 0.007849009707570076\n",
      "step = 41800: loss = 0.9714248180389404\n",
      "step = 42000: loss = 0.006503857206553221\n",
      "step = 42000: Average Return = 1.60\n",
      "step = 42200: loss = 0.01975955069065094\n",
      "step = 42400: loss = 0.018910493701696396\n",
      "step = 42600: loss = 0.013689834624528885\n",
      "step = 42800: loss = 0.007051689084619284\n",
      "step = 43000: loss = 0.011158695444464684\n",
      "step = 43000: Average Return = -1.00\n",
      "step = 43200: loss = 0.011513566598296165\n",
      "step = 43400: loss = 0.008080280385911465\n",
      "step = 43600: loss = 0.007158668711781502\n",
      "step = 43800: loss = 0.0649733617901802\n",
      "step = 44000: loss = 0.011247015558183193\n",
      "step = 44000: Average Return = -1.00\n",
      "step = 44200: loss = 0.005799190606921911\n",
      "step = 44400: loss = 0.009576666168868542\n",
      "step = 44600: loss = 0.03698338568210602\n",
      "step = 44800: loss = 0.031063184142112732\n",
      "step = 45000: loss = 0.007540276274085045\n",
      "step = 45000: Average Return = -1.00\n",
      "step = 45200: loss = 0.0068705882877111435\n",
      "step = 45400: loss = 0.019414998590946198\n",
      "step = 45600: loss = 0.036774300038814545\n",
      "step = 45800: loss = 0.041818082332611084\n",
      "step = 46000: loss = 0.009097903035581112\n",
      "step = 46000: Average Return = -1.00\n",
      "step = 46200: loss = 0.054128456860780716\n",
      "step = 46400: loss = 0.010859521105885506\n",
      "step = 46600: loss = 0.012207933701574802\n",
      "step = 46800: loss = 0.0843287780880928\n",
      "step = 47000: loss = 0.024257473647594452\n",
      "step = 47000: Average Return = -1.00\n",
      "step = 47200: loss = 0.00576529186218977\n",
      "step = 47400: loss = 0.004530780017375946\n",
      "step = 47600: loss = 0.009098093025386333\n",
      "step = 47800: loss = 0.006531483493745327\n",
      "step = 48000: loss = 0.0723751038312912\n",
      "step = 48000: Average Return = -1.00\n",
      "step = 48200: loss = 0.019062668085098267\n",
      "step = 48400: loss = 0.006678515113890171\n",
      "step = 48600: loss = 0.017533252015709877\n",
      "step = 48800: loss = 0.006390678696334362\n",
      "step = 49000: loss = 0.006901581771671772\n",
      "step = 49000: Average Return = -30.90\n",
      "step = 49200: loss = 0.019308889284729958\n",
      "step = 49400: loss = 0.006424554158002138\n",
      "step = 49600: loss = 0.005516876466572285\n",
      "step = 49800: loss = 0.012718734331429005\n",
      "step = 50000: loss = 0.007054293528199196\n",
      "step = 50000: Average Return = -1.00\n",
      "step = 50200: loss = 0.030399542301893234\n",
      "step = 50400: loss = 0.01884637027978897\n",
      "step = 50600: loss = 0.01979656144976616\n",
      "step = 50800: loss = 0.005552044603973627\n",
      "step = 51000: loss = 0.04859498143196106\n",
      "step = 51000: Average Return = -1.00\n",
      "step = 51200: loss = 0.016108322888612747\n",
      "step = 51400: loss = 0.036544572561979294\n",
      "step = 51600: loss = 0.014246105216443539\n",
      "step = 51800: loss = 0.020018918439745903\n",
      "step = 52000: loss = 0.005381681956350803\n",
      "step = 52000: Average Return = -1.00\n",
      "step = 52200: loss = 0.013342548161745071\n",
      "step = 52400: loss = 0.02022603526711464\n",
      "step = 52600: loss = 0.007344490848481655\n",
      "step = 52800: loss = 0.031113939359784126\n",
      "step = 53000: loss = 0.0071589890867471695\n",
      "step = 53000: Average Return = -1.00\n",
      "step = 53200: loss = 0.019317585974931717\n",
      "step = 53400: loss = 0.01943797431886196\n",
      "step = 53600: loss = 0.006185465957969427\n",
      "step = 53800: loss = 0.008375605568289757\n",
      "step = 54000: loss = 0.011496419087052345\n",
      "step = 54000: Average Return = -30.90\n",
      "step = 54200: loss = 0.014548217877745628\n",
      "step = 54400: loss = 0.007290732581168413\n",
      "step = 54600: loss = 0.03761462867259979\n",
      "step = 54800: loss = 0.010124888271093369\n",
      "step = 55000: loss = 0.007860957644879818\n",
      "step = 55000: Average Return = -1.00\n",
      "step = 55200: loss = 0.052724193781614304\n",
      "step = 55400: loss = 0.31991317868232727\n",
      "step = 55600: loss = 0.005966011434793472\n",
      "step = 55800: loss = 0.03816123679280281\n",
      "step = 56000: loss = 0.0225270576775074\n",
      "step = 56000: Average Return = -30.90\n",
      "step = 56200: loss = 0.018576649948954582\n",
      "step = 56400: loss = 0.022619575262069702\n",
      "step = 56600: loss = 0.008822076953947544\n",
      "step = 56800: loss = 0.013244345784187317\n",
      "step = 57000: loss = 0.007622969802469015\n",
      "step = 57000: Average Return = -1.00\n",
      "step = 57200: loss = 0.01225319691002369\n",
      "step = 57400: loss = 0.0072566913440823555\n",
      "step = 57600: loss = 0.018987346440553665\n",
      "step = 57800: loss = 0.006609643809497356\n",
      "step = 58000: loss = 0.02663748525083065\n",
      "step = 58000: Average Return = -1.00\n",
      "step = 58200: loss = 0.00830574706196785\n",
      "step = 58400: loss = 0.009217169135808945\n",
      "step = 58600: loss = 0.006841892842203379\n",
      "step = 58800: loss = 0.06172698736190796\n",
      "step = 59000: loss = 0.007005403749644756\n",
      "step = 59000: Average Return = -1.00\n",
      "step = 59200: loss = 0.006057672202587128\n",
      "step = 59400: loss = 0.05769135802984238\n",
      "step = 59600: loss = 0.17445781826972961\n",
      "step = 59800: loss = 0.4521637260913849\n",
      "step = 60000: loss = 0.02463456057012081\n",
      "step = 60000: Average Return = -1.00\n",
      "step = 60200: loss = 0.007098679430782795\n",
      "step = 60400: loss = 0.022789031267166138\n",
      "step = 60600: loss = 0.01116027683019638\n",
      "step = 60800: loss = 0.012979196384549141\n",
      "step = 61000: loss = 0.01774900034070015\n",
      "step = 61000: Average Return = -1.00\n",
      "step = 61200: loss = 0.0060157328844070435\n",
      "step = 61400: loss = 0.07650333642959595\n",
      "step = 61600: loss = 0.02037663757801056\n",
      "step = 61800: loss = 0.013474252074956894\n",
      "step = 62000: loss = 0.007979458197951317\n",
      "step = 62000: Average Return = -1.00\n",
      "step = 62200: loss = 0.006581506691873074\n",
      "step = 62400: loss = 0.0052971988916397095\n",
      "step = 62600: loss = 0.02111763134598732\n",
      "step = 62800: loss = 0.06101338565349579\n",
      "step = 63000: loss = 0.024118442088365555\n",
      "step = 63000: Average Return = -1.00\n",
      "step = 63200: loss = 0.006565166171640158\n",
      "step = 63400: loss = 0.007253163959830999\n",
      "step = 63600: loss = 0.009001994505524635\n",
      "step = 63800: loss = 0.006683085113763809\n",
      "step = 64000: loss = 0.5632901191711426\n",
      "step = 64000: Average Return = -1.00\n",
      "step = 64200: loss = 0.031946342438459396\n",
      "step = 64400: loss = 0.007362029515206814\n",
      "step = 64600: loss = 0.10269951820373535\n",
      "step = 64800: loss = 0.04252034053206444\n",
      "step = 65000: loss = 0.05269681289792061\n",
      "step = 65000: Average Return = -30.90\n",
      "step = 65200: loss = 0.006973715499043465\n",
      "step = 65400: loss = 0.019219476729631424\n",
      "step = 65600: loss = 0.005956874694675207\n",
      "step = 65800: loss = 0.05891650915145874\n",
      "step = 66000: loss = 0.030225427821278572\n",
      "step = 66000: Average Return = -1.00\n",
      "step = 66200: loss = 0.021794801577925682\n",
      "step = 66400: loss = 0.027357790619134903\n",
      "step = 66600: loss = 0.019720491021871567\n",
      "step = 66800: loss = 0.009336909279227257\n",
      "step = 67000: loss = 0.007053023669868708\n",
      "step = 67000: Average Return = -1.00\n",
      "step = 67200: loss = 0.006732124835252762\n",
      "step = 67400: loss = 0.020487507805228233\n",
      "step = 67600: loss = 0.006289882585406303\n",
      "step = 67800: loss = 0.006595291197299957\n",
      "step = 68000: loss = 0.015479439869523048\n",
      "step = 68000: Average Return = -1.00\n",
      "step = 68200: loss = 0.011786075308918953\n",
      "step = 68400: loss = 0.005272107198834419\n",
      "step = 68600: loss = 0.006569420453161001\n",
      "step = 68800: loss = 0.006172127090394497\n",
      "step = 69000: loss = 0.00662645511329174\n",
      "step = 69000: Average Return = -1.00\n",
      "step = 69200: loss = 0.01864924281835556\n",
      "step = 69400: loss = 0.006629101932048798\n",
      "step = 69600: loss = 0.009373506531119347\n",
      "step = 69800: loss = 0.006313936784863472\n",
      "step = 70000: loss = 0.006294144317507744\n",
      "step = 70000: Average Return = 1.60\n",
      "step = 70200: loss = 0.008616723120212555\n",
      "step = 70400: loss = 0.007009780965745449\n",
      "step = 70600: loss = 0.005984436720609665\n",
      "step = 70800: loss = 0.006734166294336319\n",
      "step = 71000: loss = 0.006795689929276705\n",
      "step = 71000: Average Return = -1.00\n",
      "step = 71200: loss = 0.03820793330669403\n",
      "step = 71400: loss = 0.006633528508245945\n",
      "step = 71600: loss = 0.04481580853462219\n",
      "step = 71800: loss = 0.006327820476144552\n",
      "step = 72000: loss = 0.04153348505496979\n",
      "step = 72000: Average Return = 1.60\n",
      "step = 72200: loss = 0.008061372675001621\n",
      "step = 72400: loss = 0.00586072588339448\n",
      "step = 72600: loss = 0.006493380293250084\n",
      "step = 72800: loss = 0.006162289530038834\n",
      "step = 73000: loss = 0.006795568857342005\n",
      "step = 73000: Average Return = -1.00\n",
      "step = 73200: loss = 0.019005179405212402\n",
      "step = 73400: loss = 0.10972897708415985\n",
      "step = 73600: loss = 0.010082210414111614\n",
      "step = 73800: loss = 0.007296963129192591\n",
      "step = 74000: loss = 0.06681551039218903\n",
      "step = 74000: Average Return = -1.00\n",
      "step = 74200: loss = 0.00602263119071722\n",
      "step = 74400: loss = 0.007186111994087696\n",
      "step = 74600: loss = 0.015093529596924782\n",
      "step = 74800: loss = 0.015462609007954597\n",
      "step = 75000: loss = 0.042993202805519104\n",
      "step = 75000: Average Return = -28.30\n",
      "step = 75200: loss = 0.007075563073158264\n",
      "step = 75400: loss = 0.01757805049419403\n",
      "step = 75600: loss = 0.039480287581682205\n",
      "step = 75800: loss = 0.050105802714824677\n",
      "step = 76000: loss = 0.008848767727613449\n",
      "step = 76000: Average Return = -1.00\n",
      "step = 76200: loss = 0.03826286643743515\n",
      "step = 76400: loss = 0.03211888298392296\n",
      "step = 76600: loss = 0.02521512657403946\n",
      "step = 76800: loss = 0.008524233475327492\n",
      "step = 77000: loss = 0.005732467398047447\n",
      "step = 77000: Average Return = -1.00\n",
      "step = 77200: loss = 0.01742326281964779\n",
      "step = 77400: loss = 0.009652521461248398\n",
      "step = 77600: loss = 0.02022234909236431\n",
      "step = 77800: loss = 0.010935517027974129\n",
      "step = 78000: loss = 0.015759948641061783\n",
      "step = 78000: Average Return = 1.60\n",
      "step = 78200: loss = 0.00696901511400938\n",
      "step = 78400: loss = 0.019051650539040565\n",
      "step = 78600: loss = 0.006004979833960533\n",
      "step = 78800: loss = 0.006876261439174414\n",
      "step = 79000: loss = 0.018236415460705757\n",
      "step = 79000: Average Return = -1.00\n",
      "step = 79200: loss = 0.023581404238939285\n",
      "step = 79400: loss = 0.006879763677716255\n",
      "step = 79600: loss = 0.005887625738978386\n",
      "step = 79800: loss = 0.0054858531802892685\n",
      "step = 80000: loss = 0.057397935539484024\n",
      "step = 80000: Average Return = 1.60\n",
      "step = 80200: loss = 0.006221028510481119\n",
      "step = 80400: loss = 0.0065763602033257484\n",
      "step = 80600: loss = 0.017637837678194046\n",
      "step = 80800: loss = 0.023922652006149292\n",
      "step = 81000: loss = 0.007747761905193329\n",
      "step = 81000: Average Return = 1.60\n",
      "step = 81200: loss = 0.008727174252271652\n",
      "step = 81400: loss = 0.018628675490617752\n",
      "step = 81600: loss = 0.07177075743675232\n",
      "step = 81800: loss = 0.01904749497771263\n",
      "step = 82000: loss = 0.033513642847537994\n",
      "step = 82000: Average Return = -1.00\n",
      "step = 82200: loss = 0.005857956595718861\n",
      "step = 82400: loss = 0.011942639946937561\n",
      "step = 82600: loss = 0.005682841874659061\n",
      "step = 82800: loss = 0.006958705373108387\n",
      "step = 83000: loss = 0.04718059301376343\n",
      "step = 83000: Average Return = -1.00\n",
      "step = 83200: loss = 0.009911350905895233\n",
      "step = 83400: loss = 0.007155260071158409\n",
      "step = 83600: loss = 0.022453995421528816\n",
      "step = 83800: loss = 0.03422756865620613\n",
      "step = 84000: loss = 0.03420780226588249\n",
      "step = 84000: Average Return = -1.00\n",
      "step = 84200: loss = 0.010352653451263905\n",
      "step = 84400: loss = 0.046548761427402496\n",
      "step = 84600: loss = 0.024273976683616638\n",
      "step = 84800: loss = 0.005166460759937763\n",
      "step = 85000: loss = 0.007321452256292105\n",
      "step = 85000: Average Return = -1.00\n",
      "step = 85200: loss = 0.007165164686739445\n",
      "step = 85400: loss = 0.006917351856827736\n",
      "step = 85600: loss = 0.021357806399464607\n",
      "step = 85800: loss = 0.005347665399312973\n",
      "step = 86000: loss = 0.004710236564278603\n",
      "step = 86000: Average Return = -1.00\n",
      "step = 86200: loss = 0.007690164726227522\n",
      "step = 86400: loss = 0.01048319786787033\n",
      "step = 86600: loss = 0.05493376776576042\n",
      "step = 86800: loss = 0.010232176631689072\n",
      "step = 87000: loss = 0.1628425121307373\n",
      "step = 87000: Average Return = -1.00\n",
      "step = 87200: loss = 0.035307515412569046\n",
      "step = 87400: loss = 0.00980743020772934\n",
      "step = 87600: loss = 0.23939628899097443\n",
      "step = 87800: loss = 0.005855556111782789\n",
      "step = 88000: loss = 0.005919796414673328\n",
      "step = 88000: Average Return = -1.00\n",
      "step = 88200: loss = 0.040004897862672806\n",
      "step = 88400: loss = 0.06043056398630142\n",
      "step = 88600: loss = 0.010004307143390179\n",
      "step = 88800: loss = 0.006348010618239641\n",
      "step = 89000: loss = 1.6611827611923218\n",
      "step = 89000: Average Return = -1.00\n",
      "step = 89200: loss = 0.008916731923818588\n",
      "step = 89400: loss = 0.004602918867021799\n",
      "step = 89600: loss = 0.04152825474739075\n",
      "step = 89800: loss = 0.01805644854903221\n",
      "step = 90000: loss = 0.009387614205479622\n",
      "step = 90000: Average Return = -1.00\n",
      "step = 90200: loss = 0.05155068635940552\n",
      "step = 90400: loss = 0.029216257855296135\n",
      "step = 90600: loss = 0.01132204569876194\n",
      "step = 90800: loss = 0.07240328192710876\n",
      "step = 91000: loss = 0.03800926357507706\n",
      "step = 91000: Average Return = -1.00\n",
      "step = 91200: loss = 0.18976908922195435\n",
      "step = 91400: loss = 0.006168895401060581\n",
      "step = 91600: loss = 0.12203141301870346\n",
      "step = 91800: loss = 0.010712987743318081\n",
      "step = 92000: loss = 0.035496048629283905\n",
      "step = 92000: Average Return = 1.60\n",
      "step = 92200: loss = 0.022680897265672684\n",
      "step = 92400: loss = 0.0065772514790296555\n",
      "step = 92600: loss = 0.1292029619216919\n",
      "step = 92800: loss = 0.00509326346218586\n",
      "step = 93000: loss = 0.00923941470682621\n",
      "step = 93000: Average Return = -1.00\n",
      "step = 93200: loss = 0.006189676932990551\n",
      "step = 93400: loss = 0.006734444294124842\n",
      "step = 93600: loss = 0.007984439842402935\n",
      "step = 93800: loss = 0.011343017220497131\n",
      "step = 94000: loss = 0.0351809486746788\n",
      "step = 94000: Average Return = -1.00\n",
      "step = 94200: loss = 0.00783845130354166\n",
      "step = 94400: loss = 0.01998976804316044\n",
      "step = 94600: loss = 0.007193955592811108\n",
      "step = 94800: loss = 0.04473673552274704\n",
      "step = 95000: loss = 0.0064488486386835575\n",
      "step = 95000: Average Return = -1.00\n",
      "step = 95200: loss = 0.005354149267077446\n",
      "step = 95400: loss = 0.01853145658969879\n",
      "step = 95600: loss = 0.07064911723136902\n",
      "step = 95800: loss = 0.007203582674264908\n",
      "step = 96000: loss = 0.006337023340165615\n",
      "step = 96000: Average Return = -1.00\n",
      "step = 96200: loss = 0.0070519340224564075\n",
      "step = 96400: loss = 0.05041635036468506\n",
      "step = 96600: loss = 0.06274070590734482\n",
      "step = 96800: loss = 0.05024359002709389\n",
      "step = 97000: loss = 0.09029626846313477\n",
      "step = 97000: Average Return = 1.60\n",
      "step = 97200: loss = 0.00762271648272872\n",
      "step = 97400: loss = 0.006115422118455172\n",
      "step = 97600: loss = 0.04287831485271454\n",
      "step = 97800: loss = 0.007162341382354498\n",
      "step = 98000: loss = 0.033278148621320724\n",
      "step = 98000: Average Return = 1.60\n",
      "step = 98200: loss = 0.011028561741113663\n",
      "step = 98400: loss = 0.006403080187737942\n",
      "step = 98600: loss = 0.019710583612322807\n",
      "step = 98800: loss = 0.0069418721832334995\n",
      "step = 99000: loss = 0.1735312044620514\n",
      "step = 99000: Average Return = -1.00\n",
      "step = 99200: loss = 0.13598236441612244\n",
      "step = 99400: loss = 0.007579308934509754\n",
      "step = 99600: loss = 0.02551020123064518\n",
      "step = 99800: loss = 0.005349436774849892\n",
      "step = 100000: loss = 0.008266471326351166\n",
      "step = 100000: Average Return = 1.60\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, agent.collect_policy)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience)\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1:.2f}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-32.52499960064888, 550.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (10, 10) to (16, 16) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <video width=\"640\" height=\"480\" controls>\n",
       "    <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAKvJtZGF0AAACrQYF//+p3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1OSByMjk5MSAxNzcxYjU1IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxOSAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTEgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTI1LjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAABJZYiEAf+Hdij/4SfFsgKXYLOlKAtghY81bkEPLOZSaZcRHiSjA7HdGwzuTPOZ9NgREFVaqH1HUJVS0CX0XFa4u0X9x8oILqRFIQAAAAdBmiJsV6aAAAAAJQGeQXkn/XpJlnegYY/oKCsZGU5QrEXo/pGal3nErDEjalSGpF0AAAAwQZpDPCGTKYV/9ZNzC1r6ciPb+Cj2DSdJHE/UlC6QAt2wsLGVJf8PFhzpJX/xWRuAAAAALkGaZUnhDyZTBT//6goD9QFfSbWlFbGSI9nZMkN+gAicXSZk8XyfyK5AaSimsx8AAAAiAZ6Eakn//Peo3aqy1qSlzJrJUi9oLsSB3AQD2Qk3Ty2ckQAAACZBmodJ4Q8mUwU//8gsLoDpvTye6m1UdVys1aRjQAI8a2vHm9RVOwAAAB4BnqZqSf/5Pd8azfzZsxfLD+3SJS9fhN7yFZIcp3EAAAAwQZqrSeEPJlMC/+YDmsYjJkp+zZ3nbYNYDrnULaK713QdL4/7PQZrord/pir1lTQ2AAAAD0GeyUURPX/8b6PFhEB5mwAAAAwBnuh0Sf/5OxJ6ulMAAAALAZ7qakn//FAZyScAAAAYQZrsSahBaJlMD//J/Plxlz1qw0u/nUhgAAAAFkGbDUnhClJlMCv/0Ya4w1gdAWeM0X8AAAAVQZsuSeEOiZTAr/uNQFSI8eruuYDpAAAAKUGbUknhDyZTA//xLGcqeNBq8mM1IR+9tc7aq/5gIZBUH8pP6hFoMBSlAAAAJkGfcEURPX/8ZA37eWr3ScX6G4uRJiVU1ZedFzNhU88RuGqrNicMAAAAIQGfj3RJ//kHhsEJ0ytJPjJC7UggL2N+M18gY8s7LRD5QgAAAAsBn5FqSf/8SSkpgQAAACJBm5RJqEFomUwU9f+72BthhrMdHHBa0z1+ELuj+Yn0RlhAAAAACQGfs2pJ//LAYAAAACpBm7hJ4QpSZTA/xizWCGfH47KZmZVzJ0kepT8YvYkjh2AipHpGl5yGyKEAAAAYQZ/WRTRMn/lRqgi/6Y5LXfbyo8PcwtdAAAAADAGf9XRJ//mbHK/CgQAAAA4Bn/dqSf/4kiYytp/GYQAAABlBm/lJqEFomUwP//E+s+aLO0T6JQpwGWRAAAAAG0GaHUnhClJlMCv/9lGl001GUH6fse36+sI69QAAAA9BnjtFNE3/6Y+by0u5/sAAAAAJAZ5adEn/6CLhAAAACAGeXGpJ/+WBAAAAH0GaXkmoQWiZTAk/sp7H6f+duqeBqzyhqTQ/a7nRdYQAAAAoQZphSeEKUmUwL//z3E76FrVeumirA2ycMakw0bTPVPiGcUDGWH5wmwAAAAxBnp9FNEyf+U/fwoEAAAALAZ6gakn/+QojGXAAAAAZQZqiSahBaJlMD//6o0AIrGiYzC0x1yHZLQAAABBBmsNJ4QpSZTAr//JNiXhAAAAAGkGa5UnhDomUwU0TJ/vf1qYj6xcQE6A5apJhAAAAEwGfBGpJ//ma5wfzjKKfJnyV2IUAAAAeQZsISeEPJlMC/8aIC8k63XEBrWcRRHowBCg83YCBAAAADEGfJkURPJ/5T9/CgQAAAAsBn0dqSf/5mwIZgAAAABVBm0lJqEFomUwP//qjQAhEUubGrdAAAAAVQZtqSeEKUmUwK//yTYmBstEI6e5BAAAAG0GbjEnhDomUwU0TJ/vf1nWDmlOlwl/HMqBjyAAAABMBn6tqSf/5Uwzf6nZbsg3q1liAAAAAH0Gbr0nhDyZTAl+YcwZ3rMLpy9f/cjJI0JrRuSV6nIEAAAAMQZ/NRRE8n/lP38KBAAAACwGf7mpJ//kKIDwxAAAAGUGb8kmoQWiZTAv/+mRCDLg3P+YwdRcxdiAAAAAKQZ4QRREtf+yioAAAAAwBnjFqSf/5Ch9fYFEAAAAVQZozSahBbJlMC//vPZKXkgxWBQeAAAAAHEGaV0nhClJlMD/2OTUPCcZB7Sv89Kv/7gGQ7oAAAAAKQZ51RTRN/+mMIQAAAAkBnpR0Sf/oIuAAAAAIAZ6Wakn/5YEAAAAjQZqZSahBaJlMFPX/u9gbYYbAc0n8FrTK98wV4mSs7ozeqEEAAAAJAZ64akn/8sBgAAAAZmWIggAb/2fiDGYFQGLfmkwUy47hOggPTkxGo9DUWzG2lNTyHyKK09xN+Rsa/Iu3DoaaR+JU15sfLQklT9oG3n7YZPpEDY1AJqdCZcem17AG88XWMMaaYsA5//lAi7euCJhNZoiQwQAAAAdBmiRsX5eAAAAAB0GeQniv44EAAAALAZ5hdEn//FBoEycAAAALAZ5jakn/+VN0DU4AAAAhQZpoSahBaJlMC//u5mtGZ6VRAX9qsqEii/6DLWIHAUOAAAAAFEGehkURLf/0TGGPec9LH+dN5oTJAAAACgGepXRJ//lTaIcAAAALAZ6nakn//Gm5PcEAAAAOQZqsSahBbJlMC//BM4QAAAAKQZ7KRRUv//FFMQAAAAgBnul0Sf/lgQAAAA4BnutqSf/5U1Oi6UpkPwAAAB5Bmu1JqEFsmUwJf/kMI1dkvuI2DA0z9++u5nyjHCEAAAAUQZsRSeEKUmUwJ//qr/VxCB/MQ/AAAAALQZ8vRTRP//aJswkAAAAMAZ9OdEn/+OdrElxnAAAAEgGfUGpJ//xPeFWE3KnYX7Z/kAAAAA5Bm1NJqEFomUwU8v+SgAAAABIBn3JqSf/8aYyzoW5U7C/bP8kAAAAaQZt0SeEKUmUwJf/wmYC2OLBcttyMOHKJYCEAAAAgQZuYSeEOiZTAif9npwjAoedVw0/FQLKuWls/OQsYTtEAAAAKQZ+2RRE9/+mMIAAAAAkBn9V0Sf/oIuAAAAAIAZ/Xakn/5YEAAAANQZvcSahBaJlMCX+SgAAAAAlBn/pFES//4oAAAAAIAZ4ZdEn/5YEAAAAIAZ4bakn/5YAAAAAkQZoASahBbJlMCv+716jjjWOan8Fqg4bYomSoeNTfGSw3nKiBAAAACkGePkUVLf/vtXkAAAAIAZ5ddEn/5YAAAAAJAZ5fakn/8sBhAAAALkGaREmoQWyZTAv/89QK9u/XQqAY0SWCCC1/oRl1k7LZmP+ntpk9ASpWpu7sQIAAAAAVQZ5iRRUv//aM+fzu/nIP7clmYtOhAAAACwGegXRJ//lTU+hPAAAADAGeg2pJ//jotEnOpgAAABhBmoVJqEFsmUwP//E4hy+ZBNtBicjrdjAAAAAUQZqmSeEKUmUwP/U6mAVtzTVOFKEAAAAWQZrJSeEOiZTAr/vtUG/xy4UduzwoKAAAABtBnudFET//9o8ME72IaFIar/mAhjwqlqSchHEAAAAJAZ8Iakn/8sBgAAAAMEGbDUmoQWiZTAv/xlyAPbLE8dyoBjRJYIIMNubkcWUGc2Y9DY156ALQoqlakyftAwAAAApBnytFES//6xphAAAADAGfSnRJ//kJ7GdCcQAAAAwBn0xqSf/5mxEvwoEAAAAWQZtOSahBbJlMC//vTJpq6OVTukT9gAAAAB9Bm29J4QpSZTAv/+9Ds+eL3ya+DE0PSXkM3VPJQpWAAAAAFUGbkEnhDomUwP/xOIctpVq2GvpnXQAAAB5Bm7RJ4Q8mUwP/+06LS3yQppTWuYT3bPoYTzNPPlAAAAAYQZ/SRRE9//U/GDvS3TgPiVqQUGzwrQs6AAAACQGf8XRJ/+gi4QAAAAkBn/NqSf/ywGEAAABiZYiEAE/ay1cygnIz6lvB/BTmehzgh8ndxPkR2cq0Qea4uT1UNufx1EhnIa+gSqDuW3kZ1895GWOtNeHeqMjiYosRLbeZboLARm0VOJ5UKWT1Yk/YGy9NsURH0b7Ih5iFKoEAAAAYQZohbEv/83BfjWXu3gGPquHVdkQpWVQQAAAALkGaRDwhkymF//rOs2ZqF/DdKgA1IsRX379O8gVHcVjBq+AVFAv1mNxUqaKyf4wAAAAMQZ5ialPX9yln1psRAAAACwGeg2pJ//xodIjgAAAAF0GahUmoQWiZTAv/8/HM8tEBYYZYyjzCAAAAHUGaqUnhClJlMCX/8+vxJ/S+j2R48l6cfZG+rhf1AAAACkGex0U0Tf/pjCAAAAAJAZ7mdEn/6CLhAAAACAGe6GpJ/+WBAAAAIkGa7UmoQWiZTAk/sp7H6f+dikxYxbTNjKh+nFEo+UiQhjQAAAAKQZ8LRREt/++1eQAAAAgBnyp0Sf/lgAAAAAkBnyxqSf/ywGEAAAApQZswSahBbJlMC//z3E76FrVeumirA2ycMakw0bTPVPiGZZvcMsPuhIEAAAAMQZ9ORRUsn/lP38KAAAAACgGfb2pJ//lTaIcAAAAhQZtzSahBbJlMCJ9xtDDR8I8mBD7V4LyeIA8dfuw51UgvAAAADkGfkUUVLJ/8abiyYyH8AAAACQGfsmpJ/+klwQAAAA1Bm7dJqEFsmUwJf5KAAAAACUGf1UUVL//igQAAAAgBn/R0Sf/lgQAAAAgBn/ZqSf/lgQAAACRBm/tJqEFsmUwJP7KeTDn/nbqndCWp29sqH6cZexfJWRWkG0EAAAAKQZ4ZRRUt/++1eAAAAAgBnjh0Sf/lgAAAAAkBnjpqSf/ywGEAAAApQZo+SahBbJlMC//GXHNlysOt/OmirA2ycMakw0adS4dLb2ACifFHmUIAAAAMQZ5cRRUsn/lP38KAAAAACgGefWpJ//lTaIcAAAAbQZpgSahBbJlMFE//8OHXb2T+mOywurFMdL/tAAAACwGen2pJ//xpuT3BAAAAF0GagUnhClJlMD/1OpfbEULZW5LTVOHkAAAAIEGao0nhDomUwU0T//tOi0t8kKaEfl1cALsUMHsuXHVAAAAADQGewmpJ//ma9pKHvD8AAAA0QZrHSeEPJlMCf+M/VUhPNXIjykQD3BC3yzGpblBpGmnvBweU4pah16pLlkZjYzxIIip71gAAAApBnuVFET//6xpgAAAACwGfBHRJ//lTU+hPAAAADAGfBmpJ//kKIiX4UAAAAA5BmwlJqEFomUwU8v+SgQAAAAsBnyhqSf/5U1PoTwAAAC9Bmy1J4QpSZTA/8PWBsO3EnH5NrW1feA/k+U7cfwiyYIms49qLWXuE/6Ij+X5agAAAAAxBn0tFNE1/+8ahfUEAAAANAZ9qdEn/+OjaQnOpgAAAAAwBn2xqSf/5B37b84EAAAAQQZtuSahBaJlMD//1OpgBIQAAABlBm5FJ4QpSZTAk//vYKcNZHQxrfPeMhmPIAAAAFEGfr0U0T//7crpU8bAh84wYYgDdAAAACQGf0GpJ//LAYQAAACtBm9RJqEFomUwJf5VdH+gw/xNgTeptyuP64u7aD2meuYeqRz+UARyVFusgAAAADEGf8kURLJ/5T9/CgQAAAAoBnhNqSf/5U2iHAAAAHkGaFUmoQWyZTAv/+mLl+mKo5ZYtNZHj/rHFPLApWQAAACNBmjdJ4QpSZTBRUv/7To1wZ0zg8PMrTHS7YoYPZRmv/vmHQQAAAAsBnlZqSf/5mvdZgQAAAGNliIIAE//ay1cygnIz6lvB/BTmehzgh8ndxPkR2cq0Qea4uT1UNufx1EhnIa+gSqDuW3kZ1895GWOtNeHeqMjiYosRLbeZboLARm0VOJ5UKWT1Yk/YGy9NsURH0b7Ih5iFKoEAAAAYQZohbEv/83BfjWXu3gGPquHVdkQpWVQQAAAALkGaRTwhkymH//sNs2Pp62NEoET1fgfyfKduP4RZMETWce3xmdcjRP+iI/l+WoAAAAALQZ5jalPX+8ahfUEAAAALAZ6CdEn//FAZgXcAAAAMAZ6Eakn/+Qd+2/OAAAAAEEGahkmoQWiZTA//9TqYASEAAAAZQZqqSeEKUmUwJP/72CnDWR8Fks+4yo4ncwAAABdBnshFNE3/+xy6dVEXjUtzpx//20BZmQAAAAkBnud0Sf/oIuAAAAAJAZ7pakn/8sBgAAAAJ0Ga7UmoQWiZTAv/+x9U50+KDc4nfxbZOGNSYaNpnqnxf1vBKQ+6EwAAAAxBnwtFESyf+U/fwoAAAAAKAZ8sakn/+VNohwAAAB1Bmy5JqEFsmUwL//pkQgy4NWkgVdTbWE5/ywJ1gQAAABNBm09J4QpSZTA/8TiHKj++eatbAAAAHUGbc0nhDomUwJP/+9/WpiPnkWHGhNX8yGZWu6CBAAAAGEGfkUURPf/7HOvfR6Xv7G8bf4E997bXUQAAAAkBn7B0Sf/oIuAAAAAJAZ+yakn/8sBhAAAAJkGbtkmoQWiZTA//+0p3xQxyWGfzbbt8O47AxMIbQsSzJ0A3Ik8FAAAADEGf1EURLJ/5T9/CgQAAAAsBn/VqSf/5CiMZcQAAAB5Bm/lJqEFsmUwL//si6zFJZ7uV8qLQpErZYp9oUdAAAAAOQZ4XRRUsn/xpuLKFkP8AAAAJAZ44akn/6SXBAAAAIEGaPEmoQWyZTAr/1CtpKpl4lWctvZQffdiTmuPtY5KAAAAACkGeWkUVLJ/ywGEAAAAJAZ57akn/8sBgAAAALEGaYEmoQWyZTAr/88v3QzWV2OK0cjg31quUEQVqvs0oViYqqrM8zsO76I3lAAAACkGenkUVLJ/pJcEAAAALAZ69dEn/+VNT6E8AAAAMAZ6/akn/+ZsRL8KBAAAAEkGaoUmoQWyZTAk/08QmWPbbTgAAAFhliIQA/3lw84KI/4Hm8kUqVNiIZRzpVXcdgyqKuKHgrAe3EqXT02+a5H6K8mAtJ/bzIClOc9hVqdL3anU/JjzLHYE5Qb2Kz33noWVe8LXHSeIE9qpe9+XgAAAAPEGaImxX8lRazFPGC+anFnzddj0HlmSoTTcX4On+ZxdeEw5tJMrxffnXgHfN83IN52+vtihn+2u8K2hfkQAAAA4BnkF5J/jaOxd3Ld31BQAAABpBmkM8IZMphJ/07/4uJ8KAtJ3GyV1+j5hfuAAAAE9BiJkC//CQtgjRoqMvIx9AMA9rGuowZ80rK2BB1LgDuqquMusJv/lRejctTSibnNql+WpBRkfKpY6XP2j48hQkUKFUDxRsO0TKgUNn2FbBAAAAK0GahUnhDyZTAr/RiXKvEBb390kvgJWv601YPrYRYoY79///uynbcU7RJKEAAAA+QZqmSeEPJlMCv+1LUdpbg5rbz3M/5HUu4uuE3HhttykYuvYjAZNdx1dQ8RjNWPLYl9FGk/J/5v7DesxN1uMAAAAlQZrHSeEPJlMCT7KeXL7nD6SmU5vp86xWv/78UQTjhFTY7wGzKAAAAEJliIIAL/GiG6H8Dyy/mGNBKsg4+7OyGppG8Ge4Q0LfYL5hqsnFflH+OChKyh5f6yWwiN5M6G772/vNXcwF110y3+AAAAAtQZohbFfINGYPcz/CHDwrktXyMjQEdJgdUtZ2SZu5Ulj2/ZTO/udmXe2tpaCBAAAAK0GaQjwhkymEn/CVfdsN0CsrTRViza6iGJ+xh+D0qUnMMMzjChmLHVegmekAAABCQZpjSeEPJlMD/8n/8CX97frNfDu5Kw3XQioESqe8v/LoT5zKlKRbGudp6JCFuNlKZr/08Qz//t6mmkvhlddoBJYdAAAATUGIoQL/7nb4LOjOOB5XrmPOMu3WFXmnIoSIEwg+SdGskT9BDVSJ7amCFfhVGlOpn2unWNEHj/9Qan6cc/kko5hbggRKQGuzF+xFUtfhAAAAFkGapUnhDyZTAk/0+tlCxpv0vscpbLQAAABEQZrGSeEPJlMCT9H3BhaBaTHTqQbvvTb57KlbvdiJyOadP6d3+VaFtb1EpW+Y55/bvTB/gFd+M+A8OIG5K7Bfm7m2vjkAAAAvQZrnSeEPJlMCT/LVrzv8rcOq96KFtpC6H9qjl7Fm+iQsaH49x7MTRj+deQP2SbkAAABIZYiEAP/wZOf/CUS3DavKgvt/FoZFbum6ifyeuWCxS/mdKhi8erAwcAbFD22cY2A0fDiCJGRSWV4bqr0mik2ObJmv6fTAagz+AAAACEGaIWxJ/6uBAAAATkGIkIL/8Mi5gLh/+aHewiFXjPmi6XPXRycwBOlz/l4etVAluVCEuS3egtXrNMK2+x7YX3PvmCIqQ5pbdGlhNS1bpZ8ugrpBCYtVt1yOdAAAAA9BmmNJ4Q8mUwJP8u+cQOEAAABYQYihA/9z84zT0IFrYHnRTYZcUcP/MVf3XvpUuCx9ImFhZcQ2zWL3mwTBL/jYCBrcJkFgdcsdrCYpo5NinX33qGUrmIF+pgIWwV1tEacdF9E4iNom4wfzfwAAAAxBmqVJ4Q8mUwJPq4AAAABNZYiCAC+D+uf/CUEsvG2PE9N/aPOxRS8O86sqHs0CyoYA0BQB2YZSfhFO3A8lbNUv7Mzjve7jtiqnoWmDS+5PbsFp9i3Gmnn6EWGN/+AAAABKQZojbEn//mVHeHxVlANmP+MVe/wUI/orjj8X6895noLTYayzEWz52JLfwtEXhmqVrDieaZ6RiQ4x5H/ojHoLqNKcs6qrltRYKW8AAAAYQZ5BeJP//W7SNMpTQ3YIBt/wINlFD64UAAAAEgGeYmpJ//jtqYmcKiEg9kFntQAAAEFBmmRJqEFomUwJP9A3PT8xnXOLFtm++NKnigwGzrrim80Cfjlvgnj1lGvWmuZmrs77J9h/9LM/rWrPtBJRFRX/+AAAAFBliIQB/+4DsDCDf38Dx9NwrtOJOmZEV20HSFSmyORdBN1EwMbKFIkipB9YQsJJczVK0JQ9evE7/0gn6CtZ2Fc0Yk3aPDGIcnCaxoTROk0DgQAAADJBmiJsSf/GsRI81iWI9HJoIHx4U7Xd7pHi8jzjMMhY4mrH4mmsvq3lvaD/9wB11rjB2QAAABIBnkF5J/kCGxGVUawdLuDoD0EAAAA8QYiQw//2KRP/CUSxx55Oz9mHRA4eABppC6CoEJJdy6o0m7/K+dUZn4e3TaXvrUw3NJt1T4smDz+9ybD/AAAAKkGaZEnhDyZTAk+z48xp76StL8wQIFTExW4UGLgmNFc3TT0Qhfj3OCSTmAAAAEtliIIAL/Cd45ZY//NDvZYNEY5IPWg0QAxEBqA8m1HmWnvi5cgIYVfYbhPtP+E+7akj2wnmcr7nrolb691jI2fYTBdNZ/9GETQ5S2wAAAAlQZohbEn/889Bv0msTpRf/OsU7+yv+pw50v7xGVKBO9lf46n1mQAAAF1BiJCD//H1In/hKJbhHJTZYld939qKXPi0c2FsIzMme9emU5Js9IhvP7rEvdzc52q9xlJWPkcN0slktekvyieMZzuCM6uCPlsc/xj40FkousOCVnOWXyh4K5i9evwAAAAQQZpjSeEPJlMCv9QPQNAtCAAAADNBmoVJ4Q8mUwURPJ/Px/ycAYrf3m9rhcX7at1UywkG9ARTlh7m/loW9YJ3XKD86wEx6ekAAAASAZ6kakn/+QBp/pZFDVmQeZ/5AAAAWWWIhAC/7UavZ8X/A8r23YUTSeYeYiyP2Fh7uXBDCqz8fqbSMZmPX+XiyVnE/e8toIm5zaUpCoY9Zr3QtT0Wlkg/p2pkxlPRQmE1JWCt/PBy41WoriSyfO+BAAAAIUGaIWxJ/8yRmKjcxS1qFWCafDZrr+Mk0P1WhE83EsaegAAAAFFBiJCC//Dq/Vr/mh3PO5IXRouSfgRwiUaIaHgBeYeh8Gmutcj3f23jZTr05UDao9sJozoxHZ6bF+3HCaJ8XfunwOljXdrq3F3wP2Pv7lLVQnAAAAAnQZpjSeEPJlMCT7RpXRiS31zikCBs/LoOSg2iT+/xosEbOPuRHyUfAAAAWUGIoQL/7nf1noqw/geV699eCg+TQWl0Hx59Q0j0kGMqgcoZNGx7ZYKeWbofGt+KzM4bhKwKPayOY37LsBJib5yTvzy2fPd6qWtHqEVy4jEMY8/B0W31ApN8AAAAE0GapUnhDyZTAk/qQJlj1RKXLxgAAAA4QZrHSeEPJlMFET//+OBIofsMTGcMtGlKDgVdgSb5CY04AmuEocuYrM3l6x0+J9ppcoUhaINHn4EAAAAjAZ7makn//Gjmjjvrun8ryEfxV13fRTxR5LG808a6e1z68twAAAA9QZrpSeEPJlMFPJ/UzTzildwIHf3bvN7XC4v21bqi5qc/uIjvTEf3CgDlZcHIrbn6qV8izOI6bore0TTwgQAAAA4BnwhqSf/8w6ViyIkU1QAAAEtliIIAf8zBu25Xo1feYUgaurqiPcE2tlBUrcxxF03IuInqWqAS3IOcV8khSmuc+iLlMK1/+FF1mUqmAbP2RznHW3w9CrsPys2aRHMAAABRQZoibH+feFUdxJrfdAFI679bAxCnq+RwEC4+t89+eQvSJA2dydHu01kKqedbxwl/gz/9W/Jwk3UferFiGADmjlZRlYOCaQX1gubfU3GlM3+BAAAAHwGeQXkn+NpVzkm3kEX/7YCzwquXTT32eN2RaSdwyoAAAAANQZpDPCGTKYSf8qfHMQAAADNBmmRJ4Q8mUwJP7ZOkCSMlrkyx44K9QxSpCuhCqci/wNNTnTs7qbI5uetOhzi2r3qBJn8AAAAwQZqFSeEPJlMCT9Nwh3s7npt1GtSErnCfcOFnNghKOdlhwzGjb2fURfC94MXjYwvwAAAAOkGapknhDyZTAk/UZI65h4zrAWjgTzmbD+2TSltw/1pqTqaSSaniuRmCUv1k9cmEwEkYyIF9TivjmtEAAABEQZrHSeEPJlMCv7s2MACGijI9/cvo5vGiubgaKJ+NtCsupngwyIQSwU3vDbfZgIsuKPR/6LE+S7UOaqZU5wYYH1wnYoEAAAA7QZrpSeEPJlMFETyf8WK3Frl0IIBWWSmDeEGIr0aAW6vqbsCH5TkyQ5i8FAGeHlPPHhqQdyJmlNq3t1wAAAAOAZ8Iakn/+QE2q1w2J4EAAABWZYiEAL/wi6Ng0WggeV7bubE5MPwKkgGj3JJXY51oh+eiKmBU6BgfXpg3fmmdHtheqhNOqBSd8c/xqauXDF9RWT5Ul8/9qqapi205dlfFGheA8aQBQcAAAAAOQZohbEn/88WLa0KR6XsAAABjQYiQg//v7UK5cZUDE7uKnqXoKTxITD/LbsxV7bsMqPeQ8ZbaTx2AoKIlzbXqDGiFrP0IlPB8t+yE3CAaqW4rUIi/1mAWyhMIGilx2JhdmNgVQf8o0Qj4bvWaYZ8A28X1TuP5AAAANkGaZEnhDyZTBTyf7Zra3H/AQLtop3RBzEwkyDxcAkCKMXjYqW6H8ZTqXl1Vu7k8OwvPbNPCIQAAAA8BnoNqSf/42h6ZGVUZ04sAAAA1QZqFSeEPJlMCT/hGbJrrOwEQOcrY79BR17eOQZ/aBLiEn15+Ur/scLv+/9vcEU3IpdFJPGAAAABSZYiCAC/wyOa7b/mh3sv+zQ+HufgtFDQqPdq7oxoL2Wm1KxSCz6BkeshQeohj5+r1TA1TZtYS8zjB1BUJYn464Wq4MmbPWzr4JiHBjM1k6AzTwAAAACVBmiFsSf/Ubw+uYee+xJQ12r/wkaIqrHlXCJUaf/7//uUjQMSDAAAASkGIkIL/ybwK6g0Ui2L7yPmaIZpcmRKpYpdBJrWTgP0ZAGbiXs96+DquBqFgnEALoi4g1NA8OX10Qvr0efZQb8Kjk6d2ADlmyG/4AAAAG0GaY0nhDyZTAk/y756+8m/hXQX5z8WCiU0rEAAAAFlBiKEC//Sqgcyfmh3Z5VqMYp7VKL6v7a4ZXjS5I37rDf2cXjqb5k3sFRlqCU9mpnTVNm1bx/27Q1pxuj8Qw36xfOc42PlH3o4b+jc45i36B8goDXnbp2+N4QAAABRBmqVJ4Q8mUwJP1AgOBiTykw3zpQAAAEBliIQB/+ziF8bDggnxWytqwOzu3hOB8L34xoJzdzedK8wIBrCyAsJiz0rTVfGVTJ0QG/eGJGk0fLZlrZJWMJ5VAAAAKEGaIWxJ/+vsavnLiv4F7OVBKtCc4q0sGZGnwWPif9Ctvo0lkINabqAAAABTQZpDPCGTKYV//hYWrR2r9oPcz+08pjTc4zyOjJ0JzJsFONbA8OB1MrnBIJ67jR+Zo8q4i1SWUz/h1NpRbQSyxhkFyaXrz1Vy7cXABciwcA7j3sAAAAALAZ5iakn//PezxA8AAAA6QZplSeEPJlMFPJ/LOMif/qzU4gWNsF7ahGgrKNqMYpQeBABz+I20gM0JbkcT8f1rDWz/2DI0MwHDTwAAAB8BnoRqSf/5AKCtaMYZWj/1eufrRA5riwSp412WoorLAAAAOUGahknhDyZTAr/K84n8BzFKxm5lPNG10JOHSdXlti/xaXqOruaP/b9lRcAZOVXRNxKNdyo7RKpJIQAAACZBmqdJ4Q8mUwJP1f+VP38qJstgKC4q647lNn/7pm3CwT7GziD3/wAAAEhliIIAL+bb2Ws5ZSEwaz4NrsEBa1ncyrzn0+mmQUFQR+NvvqhGvPsMdjOYGaU2bZoUIGac9wTuNY8QGFQZ89L7Vjtys1v27/0AAAANQZohbEn/88kTzQIPwQAAAE5BiJCC/4K4f/CUEtFxqBTm+Pni1BeT7mAwl4p9up+IwUzmGjK1qYyqS/JbtCErPpvoosr8ZT0MV0Wsp/s4Ny4V5RurQqBBIdxMPtCFInAAAAASQZpjSeEPJlMCT9NNdxGOGbL5AAAAU0GIoQL/8KmKKqw/geWYeVRUrN5USM+jZchf6iqf9Lrv4JDuCTOwnlbhCJjyPDsrKUHZFDwU2G9SZkTtybrJ1sPIhLzjfLrukBalqORg6TnSFRbBAAAAEUGapUnhDyZTAr/RlivuRtiBAAAASWWIhAC/6CEC7PrsQPLcKw9xVxsbTuFpCuwNM2C2Suh2EGbui5BMDDSJZjQISjaps6wNxDqyVnrl9g4HB7lgekjUFk/wF59WqTEAAAAVQZohbEn/9joekGj23qFFFP/l57IEAAAAPkGaQjwhkymEn7t/FAwlOrRJ87+mf/2S8saNVOLAkL3AM3CCxSTouT5M1Cxm8HEOUzB/VTBhuQdv5XyTJCpYAAAAHkGaY0nhDyZTAk/TWrDZ7Rm/wZNqHrcXRXZTUKy5EQAAADRBmoRJ4Q8mUwJP0gi22N+dS/uN9GZZHO3gitvp30DIBwj9lu5tcNtD6lNer2LCoSHfsRSWAAAALUGapUnhDyZTA//0MjVbJPDr1BPEHMWBOECeNo+OV8KFtDvoOP3OV5wHjIZqIQAAAD5BmsdJ4Q8mUwURPJ/wkQSrldo5ggOI4dUPBqPLWIt1yvJZ+bDB+41/Cv6wC6nbc0/C1465NreuXhcqyDDDIAAAACsBnuZqSf/8TZ3QV6z0FaSv/hJ0RVWPKuEgeXN1zWdb7uZ0//6boZ0wizhBAAAAU2WIggB/8aZjbPx/gePnT47bM38weL2NUCtvEBYT1cFEFhi9698l5D1B/2m3rYsJigkwKPI+bVw3RAd1xBXmQMYkXw9b22ubjVo7EZN2Vz+jPHnXAAAAJkGaIWxJ//f2SIESHxKG/BFIiV1mF3xnmD9hIEX/cCIAIQjSdMdpAAAAREGIkIL/8oJOM1H8DyzAN1Ux/kRJT795dF0eIr1x57ioB7y28zYq9+vTVpnAGQyZvvqle+JblROiCwmz6sS2g7xMn7/BAAAAMUGaZUnhDyZTAk/4WQZs1D+TKuDs6V3hrbI3V9QaM8zV0d+Alq+E9sPu4WjZsg2RMsAAAAAfQZ6DRRE8n/2a2dMB/nQy1PPL1OZgh6W6H8ZTeQb/oAAAABABnqRqSf/8z2dUF3epKbhRAAAOn21vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAOmYAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAA3JdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAOmYAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAQAAAAEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAADpmAAAEAAAAQAAAAANQW1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAKAAACVgAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAADOxtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAysc3RibAAAAJRzdHNkAAAAAAAAAAEAAACEYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAQABAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAAC5hdmNDAWQACv/hABZnZAAKrNlehAAAAwAEAAADACg8SJZYAQAFaOvnLIsAAAAYc3R0cwAAAAAAAAABAAABKwAACAAAAABYc3RzcwAAAAAAAAASAAAAAQAAADsAAABwAAAAqAAAAMoAAADSAAAA2gAAAOAAAADlAAAA6gAAAPAAAAD6AAABBAAAAQoAAAEQAAABGAAAAR4AAAEmAAAGsGN0dHMAAAAAAAAA1AAAAAEAABAAAAAAAQAAGAAAAAABAAAIAAAAAAEAABAAAAAAAQAAGAAAAAABAAAIAAAAAAEAABgAAAAAAQAACAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAMAABAAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAQAAAAAAEAACgAAAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAQAAEAAAAAABAAAgAAAAAAIAAAgAAAAAAgAAEAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAIAAAAAACAAAIAAAAAAIAABAAAAAAAQAAGAAAAAABAAAIAAAAAAEAACAAAAAAAgAACAAAAAABAAAgAAAAAAIAAAgAAAAAAQAAEAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEAABgAAAAAAQAACAAAAAABAAAQAAAAAAEAACgAAAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEAABAAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAEAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEAACgAAAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAIAABAAAAAAAQAAIAAAAAACAAAIAAAAAAEAACgAAAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAwAAEAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAIAABAAAAAAAQAAIAAAAAACAAAIAAAAAAEAABAAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEAACAAAAAAAgAACAAAAAABAAAgAAAAAAIAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEAACAAAAAAAgAACAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAEAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAQAAAAAAEAACAAAAAAAgAACAAAAAABAAAgAAAAAAIAAAgAAAAAAQAAEAAAAAABAAAYAAAAAAEAAAgAAAAAAgAAEAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEAABAAAAAAAQAAKAAAAAABAAAQAAAAAAEAAAAAAAAAAQAACAAAAAABAAAgAAAAAAIAAAgAAAAAAgAAEAAAAAABAAAoAAAAAAEAABAAAAAAAQAAAAAAAAABAAAIAAAAAAEAACAAAAAAAgAACAAAAAABAAAgAAAAAAIAAAgAAAAAAQAAIAAAAAACAAAIAAAAAAEAACgAAAAAAQAAEAAAAAABAAAAAAAAAAEAAAgAAAAAAgAAEAAAAAABAAAYAAAAAAEAAAgAAAAAFAAAEAAAAAABAAAgAAAAAAIAAAgAAAAAAgAAEAAAAAABAAAYAAAAAAEAAAgAAAAABgAAEAAAAAABAAAYAAAAAAEAAAgAAAAABgAAEAAAAAABAAAYAAAAAAEAAAgAAAAAAQAAGAAAAAABAAAIAAAAAAEAABAAAAAAAQAAGAAAAAABAAAIAAAAAAUAABAAAAAAAQAAGAAAAAABAAAIAAAAAAMAABAAAAAAAQAAGAAAAAABAAAIAAAAAAkAABAAAAAAAQAAGAAAAAABAAAIAAAAAAEAABgAAAAAAQAACAAAAAAOAAAQAAAAAAEAABgAAAAAAQAACAAAAAADAAAQAAAAAAEAACAAAAAAAgAACAAAAAAcc3RzYwAAAAAAAAABAAAAAQAAASsAAAABAAAEwHN0c3oAAAAAAAAAAAAAASsAAAL+AAAACwAAACkAAAA0AAAAMgAAACYAAAAqAAAAIgAAADQAAAATAAAAEAAAAA8AAAAcAAAAGgAAABkAAAAtAAAAKgAAACUAAAAPAAAAJgAAAA0AAAAuAAAAHAAAABAAAAASAAAAHQAAAB8AAAATAAAADQAAAAwAAAAjAAAALAAAABAAAAAPAAAAHQAAABQAAAAeAAAAFwAAACIAAAAQAAAADwAAABkAAAAZAAAAHwAAABcAAAAjAAAAEAAAAA8AAAAdAAAADgAAABAAAAAZAAAAIAAAAA4AAAANAAAADAAAACcAAAANAAAAagAAAAsAAAALAAAADwAAAA8AAAAlAAAAGAAAAA4AAAAPAAAAEgAAAA4AAAAMAAAAEgAAACIAAAAYAAAADwAAABAAAAAWAAAAEgAAABYAAAAeAAAAJAAAAA4AAAANAAAADAAAABEAAAANAAAADAAAAAwAAAAoAAAADgAAAAwAAAANAAAAMgAAABkAAAAPAAAAEAAAABwAAAAYAAAAGgAAAB8AAAANAAAANAAAAA4AAAAQAAAAEAAAABoAAAAjAAAAGQAAACIAAAAcAAAADQAAAA0AAABmAAAAHAAAADIAAAAQAAAADwAAABsAAAAhAAAADgAAAA0AAAAMAAAAJgAAAA4AAAAMAAAADQAAAC0AAAAQAAAADgAAACUAAAASAAAADQAAABEAAAANAAAADAAAAAwAAAAoAAAADgAAAAwAAAANAAAALQAAABAAAAAOAAAAHwAAAA8AAAAbAAAAJAAAABEAAAA4AAAADgAAAA8AAAAQAAAAEgAAAA8AAAAzAAAAEAAAABEAAAAQAAAAFAAAAB0AAAAYAAAADQAAAC8AAAAQAAAADgAAACIAAAAnAAAADwAAAGcAAAAcAAAAMgAAAA8AAAAPAAAAEAAAABQAAAAdAAAAGwAAAA0AAAANAAAAKwAAABAAAAAOAAAAIQAAABcAAAAhAAAAHAAAAA0AAAANAAAAKgAAABAAAAAPAAAAIgAAABIAAAANAAAAJAAAAA4AAAANAAAAMAAAAA4AAAAPAAAAEAAAABYAAABcAAAAQAAAABIAAAAeAAAAUwAAAC8AAABCAAAAKQAAAEYAAAAxAAAALwAAAEYAAABRAAAAGgAAAEgAAAAzAAAATAAAAAwAAABSAAAAEwAAAFwAAAAQAAAAUQAAAE4AAAAcAAAAFgAAAEUAAABUAAAANgAAABYAAABAAAAALgAAAE8AAAApAAAAYQAAABQAAAA3AAAAFgAAAF0AAAAlAAAAVQAAACsAAABdAAAAFwAAADwAAAAnAAAAQQAAABIAAABPAAAAVQAAACMAAAARAAAANwAAADQAAAA+AAAASAAAAD8AAAASAAAAWgAAABIAAABnAAAAOgAAABMAAAA5AAAAVgAAACkAAABOAAAAHwAAAF0AAAAYAAAARAAAACwAAABXAAAADwAAAD4AAAAjAAAAPQAAACoAAABMAAAAEQAAAFIAAAAWAAAAVwAAABUAAABNAAAAGQAAAEIAAAAiAAAAOAAAADEAAABCAAAALwAAAFcAAAAqAAAASAAAADUAAAAjAAAAFAAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1OC4yOS4xMDA=\" type=\"video/mp4\">\n",
       "  Your browser does not support the video tag.\n",
       "  </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_py_env = suite_gym.load(env_name)\n",
    "video_env = tf_py_environment.TFPyEnvironment(video_py_env)\n",
    "\n",
    "def create_policy_eval_video(policy, filename, num_episodes=50, fps=5):\n",
    "  filename = filename + \".mp4\"\n",
    "  with imageio.get_writer(filename, fps=fps) as video:\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = video_env.reset()\n",
    "      video.append_data(video_py_env.render())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = video_env.step(action_step.action)\n",
    "        video.append_data(video_py_env.render())\n",
    "  return embed_mp4(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "create_policy_eval_video(agent.policy, \"trained-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
